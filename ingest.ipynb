{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed589d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cpu064/Documents/python/venv311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from PyPDF2 import PdfReader\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as qdrant_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c69ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"[%(levelname)s] %(message)s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e451066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def try_init_deepseek_pipeline(ocr_model_name):\n",
    "    try:\n",
    "        from transformers import pipeline\n",
    "        logging.info(\"Initializing DeepSeek OCR pipeline...\")\n",
    "        ocr = pipeline(\"image-to-text\", model=ocr_model_name, trust_remote_code=True)\n",
    "        return ocr\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"DeepSeek init failed: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d57e7d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_with_pytesseract(pil_image):\n",
    "    import pytesseract\n",
    "    return pytesseract.image_to_string(pil_image)\n",
    "\n",
    "\n",
    "def ocr_with_easyocr(pil_image, reader=None):\n",
    "    import easyocr, numpy as np\n",
    "    if reader is None:\n",
    "        reader = easyocr.Reader(['en'], gpu=False)\n",
    "    arr = np.array(pil_image)\n",
    "    res = reader.readtext(arr, detail=0)\n",
    "    return \"\\n\".join(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f2e8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_any(path, hf_pipeline=None, easyocr_reader=None):\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "\n",
    "    # Handle PDFs\n",
    "    if ext == \".pdf\":\n",
    "        try:\n",
    "            reader = PdfReader(path)\n",
    "            text = \"\\n\".join(page.extract_text() or \"\" for page in reader.pages)\n",
    "            if text.strip():\n",
    "                logging.info(f\"Extracted text from PDF: {path}\")\n",
    "                return text.strip()\n",
    "\n",
    "            logging.warning(f\"No text in {path}, running OCR...\")\n",
    "            from pdf2image import convert_from_path\n",
    "            pages = convert_from_path(path, dpi=200)\n",
    "            if pages:\n",
    "                return ocr_with_pytesseract(pages[0])\n",
    "        except Exception as e:\n",
    "            logging.error(f\"PDF extraction failed: {e}\")\n",
    "        return \"\"\n",
    "    \n",
    "      # Handle image files\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Failed to open image {path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    # Try OCR methods in order\n",
    "    for method_name, method in [\n",
    "        (\"DeepSeek\", lambda: hf_pipeline(img) if hf_pipeline else None),\n",
    "        (\"pytesseract\", lambda: ocr_with_pytesseract(img)),\n",
    "        (\"easyocr\", lambda: ocr_with_easyocr(img, reader=easyocr_reader))\n",
    "    ]:\n",
    "        try:\n",
    "            result = method()\n",
    "            if result:\n",
    "                if isinstance(result, list) and 'generated_text' in result[0]:\n",
    "                    return result[0]['generated_text']\n",
    "                return str(result)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"{method_name} failed: {e}\")\n",
    "    logging.error(f\"All OCR methods failed for {path}\")\n",
    "    return \"\"\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ca2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path=\"config.yaml\"):\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a96577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, max_chars=1000, overlap=100) -> List[str]:\n",
    "    return [\n",
    "        text[i:i + max_chars]\n",
    "        for i in range(0, len(text), max_chars - overlap)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce37010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(path, embedder, q, coll, hf_pipeline, easyocr_reader, chunk_chars, overlap, point_id_start):\n",
    "    fname = os.path.basename(path)\n",
    "    text = extract_text_any(path, hf_pipeline=hf_pipeline, easyocr_reader=easyocr_reader)\n",
    "    if not text:\n",
    "        logging.warning(f\"No text extracted from {fname}, skipping.\")\n",
    "        return 0\n",
    "\n",
    "    chunks = chunk_text(text, chunk_chars, overlap)\n",
    "    embeddings = embedder.encode(chunks, batch_size=8, show_progress_bar=False)\n",
    "    points = [\n",
    "        qdrant_models.PointStruct(\n",
    "            id=point_id_start + i,\n",
    "            vector=embeddings[i].tolist(),\n",
    "            payload={\"source_file\": fname, \"chunk_index\": i, \"text\": chunks[i][:5000]}\n",
    "        )\n",
    "        for i in range(len(chunks))\n",
    "    ]\n",
    "    q.upsert(collection_name=coll, points=points)\n",
    "    logging.info(f\"Ingested {len(chunks)} chunks from {fname}\")\n",
    "    return len(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4969a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cfg = load_config()\n",
    "    qcfg, coll = cfg[\"qdrant\"], cfg[\"qdrant\"][\"collection\"]\n",
    "    embed_model_name, ocr_model_name = cfg[\"models\"][\"embedding\"], cfg[\"models\"][\"ocr\"]\n",
    "    chunk_chars, overlap = cfg[\"ingest\"][\"chunk_chars\"], cfg[\"ingest\"][\"chunk_overlap\"]\n",
    "    docs_dir = cfg[\"docs_dir\"][\"docs_to_ingest\"]\n",
    "\n",
    "    # Initialize models\n",
    "    logging.info(f\"Loading embedding model: {embed_model_name}\")\n",
    "    embedder = SentenceTransformer(embed_model_name)\n",
    "    q = QdrantClient(url=qcfg[\"url\"], api_key=qcfg.get(\"api_key\"))\n",
    "    hf_pipeline = try_init_deepseek_pipeline(ocr_model_name)\n",
    "    import easyocr\n",
    "    easyocr_reader = easyocr.Reader(['en'], gpu=False)\n",
    "\n",
    "    # Create collection if not exists\n",
    "    vector_size = embedder.get_sentence_embedding_dimension()\n",
    "    try:\n",
    "        q.get_collection(coll)\n",
    "    except Exception:\n",
    "        q.recreate_collection(\n",
    "            collection_name=coll,\n",
    "            vectors_config=qdrant_models.VectorParams(size=vector_size, distance=qdrant_models.Distance.COSINE)\n",
    "        )\n",
    "        logging.info(f\"Created collection '{coll}'\")\n",
    "\n",
    "    # Process files\n",
    "    paths = [os.path.join(docs_dir, f) for f in os.listdir(docs_dir) if os.path.isfile(os.path.join(docs_dir, f))]\n",
    "    os.makedirs(docs_dir, exist_ok=True)\n",
    "    point_id = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        futures = {\n",
    "            executor.submit(\n",
    "                process_file, path, embedder, q, coll, hf_pipeline, easyocr_reader, chunk_chars, overlap, point_id + idx * 10000\n",
    "            ): path\n",
    "            for idx, path in enumerate(paths)\n",
    "        }\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            path = futures[future]\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to process {path}: {e}\")\n",
    "\n",
    "    logging.info(\"ingestion complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "477ff285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Loading embedding model: sentence-transformers/all-mpnet-base-v2\n",
      "[INFO] Use pytorch device_name: cuda:0\n",
      "[INFO] Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "[INFO] HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"\n",
      "[INFO] Initializing DeepSeek OCR pipeline...\n",
      "Encountered exception while importing einops: No module named 'einops'\n",
      "[WARNING] DeepSeek init failed: This modeling file requires the following packages that were not found in your environment: einops. Run `pip install einops`\n",
      "[WARNING] Using CPU. Note: This module is much faster with a GPU.\n",
      "[INFO] HTTP Request: GET http://localhost:6333/collections/documents \"HTTP/1.1 404 Not Found\"\n",
      "/tmp/ipykernel_1322500/1244741268.py:21: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  q.recreate_collection(\n",
      "[INFO] HTTP Request: DELETE http://localhost:6333/collections/documents \"HTTP/1.1 200 OK\"\n",
      "[INFO] HTTP Request: PUT http://localhost:6333/collections/documents \"HTTP/1.1 200 OK\"\n",
      "[INFO] Created collection 'documents'\n",
      "[ERROR] All OCR methods failed for /home/cpu064/Downloads/docs/Screenshot from 2025-11-04 14-53-30.png\n",
      "[WARNING] No text extracted from Screenshot from 2025-11-04 14-53-30.png, skipping.\n",
      "[ERROR] All OCR methods failed for /home/cpu064/Downloads/docs/Screenshot from 2025-11-04 15-01-30.png\n",
      "[WARNING] No text extracted from Screenshot from 2025-11-04 15-01-30.png, skipping.\n",
      "[ERROR] All OCR methods failed for /home/cpu064/Downloads/docs/Screenshot from 2025-11-04 14-51-54.png\n",
      "[WARNING] No text extracted from Screenshot from 2025-11-04 14-51-54.png, skipping.\n",
      "[ERROR] All OCR methods failed for /home/cpu064/Downloads/docs/Screenshot from 2025-11-04 14-55-30.png\n",
      "[WARNING] No text extracted from Screenshot from 2025-11-04 14-55-30.png, skipping.\n",
      "[ERROR] All OCR methods failed for /home/cpu064/Downloads/docs/Screenshot from 2025-11-04 14-49-39.png\n",
      "[WARNING] No text extracted from Screenshot from 2025-11-04 14-49-39.png, skipping.\n",
      "[ERROR] All OCR methods failed for /home/cpu064/Downloads/docs/Screenshot from 2025-11-04 14-48-17.png\n",
      "[WARNING] No text extracted from Screenshot from 2025-11-04 14-48-17.png, skipping.\n",
      "[ERROR] All OCR methods failed for /home/cpu064/Downloads/docs/Screenshot from 2025-11-04 14-59-29.png\n",
      "[WARNING] No text extracted from Screenshot from 2025-11-04 14-59-29.png, skipping.\n",
      "[ERROR] All OCR methods failed for /home/cpu064/Downloads/docs/Screenshot from 2025-11-04 15-06-10.png\n",
      "[WARNING] No text extracted from Screenshot from 2025-11-04 15-06-10.png, skipping.\n",
      "[INFO] HTTP Request: PUT http://localhost:6333/collections/documents/points?wait=true \"HTTP/1.1 200 OK\"\n",
      "[INFO] Ingested 1 chunks from Screenshot from 2025-11-04 14-45-42.png\n",
      "[INFO] ingestion complete.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311 (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
